{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Image Processing From Scratch\n",
    "\n",
    "## Introduction\n",
    "Binary image processing is a fundamental technique in computer vision that involves converting grayscale or color images into a binary (black and white) format. While this transformation might seem simple, it serves as the foundation for many advanced computer vision tasks and has numerous practical applications.\n",
    "\n",
    "In this notebook, we'll implement various thresholding algorithms from scratch using pure NumPy, which will help us understand the mathematical and algorithmic foundations of binary image processing. Rather than relying on pre-built functions, we'll create our own implementations to gain deeper insights into how these algorithms work.\n",
    "\n",
    "## Key Concepts Covered\n",
    "- Understanding image thresholding fundamentals\n",
    "- Implementing different thresholding techniques from scratch\n",
    "- Comparing and analyzing various methods\n",
    "- Exploring real-world applications\n",
    "\n",
    "## Dependencies\n",
    "We'll use minimal dependencies to focus on understanding core concepts:\n",
    "- NumPy: For numerical computations\n",
    "- Matplotlib: For visualization\n",
    "- PIL (Python Imaging Library): For image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Configure matplotlib for better display in notebook\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "First we need to create some utility functions that will help develop and test our algoirthms:\n",
    "1. Load and preprocess images\n",
    "2. Display results for comparison\n",
    "3. Analyze image characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load and convert an image to grayscale.\n",
    "    Returns:\n",
    "        numpy.ndarray: Grayscale image array with values 0-255\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode != 'L':\n",
    "                img = img.convert('L')\n",
    "            # Convert to numpy array and ensure correct dtype\n",
    "            return np.array(img, dtype=np.uint8)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing image: {str(e)}\")\n",
    "\n",
    "def display_images(images, titles=None, figsize=(15, 5), cmap='gray',border_color='black', border_width=1):\n",
    "    \"\"\"Display images in a truly compact grid layout with maximum 4 images per row.\n",
    "    \n",
    "    This function creates a highly compact display by carefully controlling both the\n",
    "    figure size and the spacing between subplots. It uses a combination of GridSpec\n",
    "    and figure size calculations to ensure images are displayed with minimal gaps\n",
    "    while maintaining readability.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of images to display\n",
    "        titles (list): Optional list of titles for each image\n",
    "        figsize (tuple): Base figure size (width, height) used as a reference for calculations\n",
    "        cmap (str): Colormap to use for displaying images\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    if titles is None:\n",
    "        titles = [f'Image {i+1}' for i in range(n)]\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    cols = min(n, 4)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    # Calculate figure size differently to ensure compact layout\n",
    "    # Use the aspect ratio of the first image to maintain proportions\n",
    "    sample_image = images[0]\n",
    "    aspect_ratio = sample_image.shape[0] / sample_image.shape[1]\n",
    "    \n",
    "    # Base width calculation considering the number of columns\n",
    "    base_unit = 4  # Base unit for size calculations\n",
    "    fig_width = base_unit * cols\n",
    "    fig_height = base_unit * aspect_ratio * rows\n",
    "    \n",
    "    # Create figure and GridSpec with tight spacing\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    gs = plt.GridSpec(rows, cols, figure=fig,\n",
    "                     left=0.01, right=0.99,\n",
    "                     bottom=0.01, top=0.90,\n",
    "                     wspace=0.01, hspace=0.15)\n",
    "    \n",
    "    # Create and populate subplots\n",
    "    for idx in range(n):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        \n",
    "        # Create subplot\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        \n",
    "        # Display image without interpolation for sharper display\n",
    "        ax.imshow(images[idx], cmap=cmap, interpolation='nearest')\n",
    "        ax.set_title(titles[idx], pad=2, fontsize=14)\n",
    "        \n",
    "        # Remove all axes elements\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "                    spine.set_visible(True)  # Make sure spine is visible\n",
    "                    spine.set_color(border_color)  # Set border color\n",
    "                    spine.set_linewidth(border_width)  # Set border width\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def analyze_image(image):\n",
    "    \"\"\"Analyze basic characteristics of an image.\n",
    "    \n",
    "    Computes and returns useful statistics about the image:\n",
    "    - Min and max pixel values\n",
    "    - Mean and median intensity\n",
    "    - Standard deviation of pixel values\n",
    "    - Histogram data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing image statistics\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'min': int(np.min(image)),\n",
    "        'max': int(np.max(image)),\n",
    "        'mean': float(np.mean(image)),\n",
    "        'median': float(np.median(image)),\n",
    "        'std': float(np.std(image))\n",
    "    }\n",
    "    \n",
    "    # Compute histogram\n",
    "    hist, bins = np.histogram(image.flatten(), bins=256, range=[0, 256])\n",
    "    stats['histogram'] = hist\n",
    "    stats['bins'] = bins\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def plot_histogram(image, title=\"Image Histogram\", figsize=(10, 4)):\n",
    "    \"\"\"Plot the histogram of a grayscale image.\n",
    "    \n",
    "    Creates a visualization of the image's intensity distribution,\n",
    "    which is crucial for understanding how to set thresholds.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input grayscale image\n",
    "        title (str): Title for the plot\n",
    "        figsize (tuple): Figure size\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.hist(image.ravel(), bins=256, range=[0, 256], density=True, alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def process_random_image(folder_path, algorithms, num_images=1, seed=None):\n",
    "    \"\"\"Process random images from a directory using specified algorithms.\n",
    "    \n",
    "    This function streamlines our testing workflow by:\n",
    "    1. Randomly selecting images from a directory\n",
    "    2. Applying multiple processing algorithms\n",
    "    3. Displaying results side by side for comparison\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the directory containing images\n",
    "        algorithms (dict): Dictionary of {name: function} pairs for processing\n",
    "                         Each function should take an image array as input\n",
    "        num_images (int): Number of random images to process\n",
    "        seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        list: List of processed image sets for further analysis if needed\n",
    "    \n",
    "    Example usage:\n",
    "        algorithms = {\n",
    "            'Basic Threshold': lambda img: basic_threshold(img, 127),\n",
    "            'Adaptive': lambda img: adaptive_threshold(img)\n",
    "        }\n",
    "        process_random_image('../images', algorithms)\n",
    "    \"\"\"\n",
    "    # Set random seed if provided\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Get list of valid image files\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    image_files = [\n",
    "        f for f in os.listdir(folder_path) \n",
    "        if f.lower().endswith(valid_extensions)\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No valid images found in {folder_path}\")\n",
    "    \n",
    "    # Process specified number of random images\n",
    "    results = []\n",
    "    for _ in range(num_images):\n",
    "        image_file = random.choice(image_files)\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        original = load_image(image_path)\n",
    "        \n",
    "        # Apply each algorithm\n",
    "        processed_images = [original]\n",
    "        titles = ['Original']\n",
    "        \n",
    "        for name, algo in algorithms.items():\n",
    "            try:\n",
    "                processed = algo(original)\n",
    "                processed_images.append(processed)\n",
    "                titles.append(name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error applying {name}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\nProcessing: {image_file}\")\n",
    "        \n",
    "        plot_histogram(original, f\"Histogram for {image_file}\")\n",
    "        \n",
    "        display_images(\n",
    "            processed_images,\n",
    "            titles,\n",
    "            figsize=(4 * len(processed_images), 4)\n",
    "        )\n",
    "        \n",
    "        stats = analyze_image(original)\n",
    "        print(\"\\nImage Statistics:\")\n",
    "        print(f\"Dimensions: {original.shape}\")\n",
    "        print(f\"Intensity Range: {stats['min']} - {stats['max']}\")\n",
    "        print(f\"Mean Intensity: {stats['mean']:.2f}\")\n",
    "        print(f\"Standard Deviation: {stats['std']:.2f}\")\n",
    "        \n",
    "        results.append({\n",
    "            'filename': image_file,\n",
    "            'original': original,\n",
    "            'processed': processed_images[1:],\n",
    "            'stats': stats\n",
    "        })\n",
    "    \n",
    "    return results   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Thresholding Algorithms Implementation\n",
    "\n",
    "We'll implement several thresholding algorithms, each with its own strengths and ideal use cases. For each algorithm, we'll:\n",
    "1. Explain the mathematical foundation\n",
    "2. Implement the algorithm from scratch\n",
    "3. Demonstrate its behavior on example images\n",
    "4. Discuss its advantages and limitations\n",
    "\n",
    "## Algorithm Categories\n",
    "\n",
    "Our implementations cover the main approaches to image thresholding:\n",
    "\n",
    "1. **Global Thresholding**: Uses a single threshold value for the entire image\n",
    "2. **Adaptive Thresholding**: Calculates different thresholds for different image regions\n",
    "3. **Statistical Methods**: Uses image statistics to determine optimal thresholds\n",
    "4. **Information Theory Methods**: Leverages entropy and information content\n",
    "5. **Geometric Methods**: Uses geometric properties of the histogram\n",
    "\n",
    "Each method addresses different challenges in image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_threshold(image, threshold, high_value=255, low_value=0):\n",
    "    \"\"\"Implement simple global thresholding.\n",
    "    \n",
    "    This is the most basic form of thresholding where we use a single global\n",
    "    threshold value. Pixels above this value become foreground (high_value),\n",
    "    while pixels below become background (low_value).\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array\")\n",
    "        \n",
    "    if image.dtype != np.uint8:\n",
    "        raise ValueError(\"Image must be 8-bit (dtype=uint8)\")\n",
    "    \n",
    "    return np.where(image > threshold, high_value, low_value).astype(np.uint8)\n",
    "\n",
    "def mean_adaptive_threshold(image, window_size=11, c=2):\n",
    "    \"\"\"Implement mean adaptive thresholding.\n",
    "    \n",
    "    This method calculates a threshold for each pixel based on the mean\n",
    "    of its neighborhood. The constant c is subtracted from the mean to\n",
    "    fine-tune the threshold.\n",
    "    \n",
    "    Mathematical formula:\n",
    "    T(x,y) = mean(neighborhood) - c\n",
    "    \n",
    "    \"\"\"\n",
    "    if window_size % 2 == 0:\n",
    "        raise ValueError(\"Window size must be odd\")\n",
    "\n",
    "    pad_size = window_size // 2\n",
    "    padded = np.pad(image, pad_size, mode='reflect')\n",
    "    \n",
    "    binary = np.zeros_like(image)\n",
    "    \n",
    "    rows, cols = image.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            neighborhood = padded[i:i + window_size, j:j + window_size]\n",
    "            threshold = np.mean(neighborhood) - c\n",
    "            binary[i, j] = 255 if image[i, j] > threshold else 0\n",
    "            \n",
    "    return binary\n",
    "\n",
    "def gaussian_adaptive_threshold(image, window_size=11, sigma=2.0, c=2):\n",
    "    \"\"\"Implement Gaussian adaptive thresholding.\n",
    "    \n",
    "    Similar to mean adaptive thresholding, but uses a weighted sum where\n",
    "    pixels closer to the center have more influence on the threshold.\n",
    "    \n",
    "    Mathematical formula:\n",
    "    T(x,y) = (G * f)(x,y) - c\n",
    "    \"\"\"\n",
    "    if window_size % 2 == 0:\n",
    "        raise ValueError(\"Window size must be odd\")\n",
    "    \n",
    "    kernel = create_gaussian_kernel(window_size, sigma)\n",
    "    \n",
    "    pad_size = window_size // 2\n",
    "    padded = np.pad(image, pad_size, mode='reflect')\n",
    "    \n",
    "    binary = np.zeros_like(image)\n",
    "    \n",
    "    rows, cols = image.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            neighborhood = padded[i:i + window_size, j:j + window_size]\n",
    "            threshold = np.sum(neighborhood * kernel) - c\n",
    "            binary[i, j] = 255 if image[i, j] > threshold else 0\n",
    "            \n",
    "    return binary\n",
    "\n",
    "def create_gaussian_kernel(size, sigma):\n",
    "    \"\"\"Create a 2D Gaussian kernel.\"\"\"\n",
    "    ax = np.linspace(-(size - 1) / 2., (size - 1) / 2., size)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    \n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def otsu_threshold(image):\n",
    "    \"\"\"Implement Otsu's thresholding method.\n",
    "    \n",
    "    Otsu's method works by minimizing the within-class variance and maximizing\n",
    "    the between-class variance of the two classes (foreground and background).\n",
    "    \n",
    "    The algorithm:\n",
    "    1. Compute histogram and probability distribution\n",
    "    2. For each possible threshold:\n",
    "        - Split pixels into two classes\n",
    "        - Calculate class means and variances\n",
    "        - Calculate between-class variance\n",
    "    3. Select threshold that maximizes between-class variance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    hist, _ = np.histogram(image.flatten(), bins=256, range=[0, 256])\n",
    "    hist = hist.astype(float)\n",
    "    hist /= np.sum(hist)\n",
    "    \n",
    "    max_variance = 0\n",
    "    optimal_threshold = 0\n",
    "    \n",
    "    cumsum = np.cumsum(hist)\n",
    "    cumsum_val = np.cumsum(hist * np.arange(256))\n",
    "    global_mean = cumsum_val[-1]\n",
    "    \n",
    "    for threshold in range(1, 255):\n",
    "        w0 = cumsum[threshold]  # Background\n",
    "        w1 = 1 - w0  # Foreground\n",
    "        \n",
    "        if w0 == 0 or w1 == 0:\n",
    "            continue\n",
    "            \n",
    "        # Class means\n",
    "        mu0 = cumsum_val[threshold] / w0\n",
    "        mu1 = (global_mean - cumsum_val[threshold]) / w1\n",
    "        \n",
    "        # Calculate between-class variance\n",
    "        variance = w0 * w1 * (mu0 - mu1) ** 2\n",
    "        \n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            optimal_threshold = threshold\n",
    "    \n",
    "    binary = simple_threshold(image, optimal_threshold)\n",
    "    return binary, optimal_threshold\n",
    "\n",
    "def multilevel_threshold(image, num_classes=3):\n",
    "    \"\"\"Implement multi-level thresholding using k-means clustering.\n",
    "    \n",
    "    This method segments the image into multiple classes rather than just\n",
    "    foreground and background. It uses k-means clustering on pixel intensities\n",
    "    to find optimal threshold values.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input grayscale image\n",
    "        num_classes (int): Number of desired classes/segments\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (segmented_image, thresholds)\n",
    "    \"\"\"\n",
    "    # Flatten image and convert to float\n",
    "    pixels = image.flatten().astype(float)\n",
    "    \n",
    "    # Initialize centroids\n",
    "    centroids = np.linspace(0, 255, num_classes)\n",
    "    old_centroids = np.zeros_like(centroids)\n",
    "    \n",
    "    # Iterate until convergence\n",
    "    max_iterations = 100\n",
    "    iteration = 0\n",
    "    \n",
    "    while not np.array_equal(old_centroids, centroids) and iteration < max_iterations:\n",
    "        old_centroids = centroids.copy()\n",
    "        \n",
    "        # Assign pixels to nearest centroid\n",
    "        distances = np.abs(pixels.reshape(-1, 1) - centroids)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Update centroids\n",
    "        for i in range(num_classes):\n",
    "            if np.sum(labels == i) > 0:\n",
    "                centroids[i] = np.mean(pixels[labels == i])\n",
    "                \n",
    "        iteration += 1\n",
    "    \n",
    "    # Create segmented image\n",
    "    segmented = centroids[labels].reshape(image.shape)\n",
    "    \n",
    "    # Calculate thresholds between centroids\n",
    "    thresholds = np.mean([centroids[:-1], centroids[1:]], axis=0)\n",
    "    \n",
    "    return segmented.astype(np.uint8), thresholds\n",
    "\n",
    "def local_threshold(image, window_size=35, k=0.2):\n",
    "    \"\"\"Implement local thresholding using Sauvola's method.\n",
    "    \n",
    "    This technique adapts to local image statistics using both mean\n",
    "    and standard deviation in a window:\n",
    "    \n",
    "    T(x,y) = mean(x,y) * (1 + k * ((std(x,y) / R) - 1))\n",
    "    \n",
    "    where R is the maximum standard deviation (128 for 8-bit images)\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input grayscale image\n",
    "        window_size (int): Size of local window\n",
    "        k (float): Sensitivity factor (0.2-0.5 typical)\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Binary image\n",
    "    \"\"\"\n",
    "    # Pad image\n",
    "    pad_size = window_size // 2\n",
    "    padded = np.pad(image, pad_size, mode='reflect')\n",
    "    \n",
    "    # Initialize output\n",
    "    binary = np.zeros_like(image)\n",
    "    \n",
    "    # Calculate threshold for each pixel\n",
    "    rows, cols = image.shape\n",
    "    R = 128  # Dynamic range for 8-bit images\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            window = padded[i:i + window_size, j:j + window_size]\n",
    "            \n",
    "            mean = np.mean(window)\n",
    "            std = np.std(window)\n",
    "            \n",
    "            # Calculate threshold using Sauvola's formula\n",
    "            threshold = mean * (1 + k * ((std / R) - 1))\n",
    "            \n",
    "            binary[i, j] = 255 if image[i, j] > threshold else 0\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def triangle_threshold(image):\n",
    "    \"\"\"Implement triangle algorithm for thresholding.\n",
    "    \n",
    "    This method:\n",
    "    1. Finds the peak in the histogram\n",
    "    2. Creates a line from peak to the last non-zero bin\n",
    "    3. Finds the point of maximum perpendicular distance from this line\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (binary_image, threshold)\n",
    "    \"\"\"\n",
    "    # Calculate histogram\n",
    "    hist, bins = np.histogram(image.flatten(), bins=256, range=[0, 256])\n",
    "    \n",
    "    # Find peak (mode)\n",
    "    peak_idx = np.argmax(hist)\n",
    "    \n",
    "    # Find last non-zero bin\n",
    "    last_idx = 255 - np.argmax(hist[::-1] > 0)\n",
    "    \n",
    "    # Create line between peak and last point\n",
    "    x1, y1 = peak_idx, hist[peak_idx]\n",
    "    x2, y2 = last_idx, hist[last_idx]\n",
    "    \n",
    "    # Calculate distances from line to histogram points\n",
    "    max_dist = 0\n",
    "    threshold = peak_idx\n",
    "    \n",
    "    for i in range(peak_idx, last_idx):\n",
    "        if y2 - y1 != 0:\n",
    "            dist = np.abs((y2-y1)*i - (x2-x1)*hist[i] + x2*y1 - y2*x1) / np.sqrt((y2-y1)**2 + (x2-x1)**2)\n",
    "        else:\n",
    "            dist = hist[i]\n",
    "            \n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            threshold = i\n",
    "    \n",
    "    binary = simple_threshold(image, threshold)\n",
    "    return binary, threshold\n",
    "\n",
    "def entropy_threshold(image):\n",
    "    \"\"\"Implement entropy-based thresholding.\n",
    "    \n",
    "    This method maximizes the sum of entropies of the foreground\n",
    "    and background distributions. The optimal threshold occurs where\n",
    "    the total entropy is maximized.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (binary_image, threshold)\n",
    "    \"\"\"\n",
    "    # Calculate histogram and probabilities\n",
    "    hist, _ = np.histogram(image.flatten(), bins=256, range=[0, 256])\n",
    "    hist = hist.astype(float)\n",
    "    hist /= np.sum(hist)\n",
    "    \n",
    "    max_entropy = 0\n",
    "    optimal_threshold = 0\n",
    "    \n",
    "    # Try each possible threshold\n",
    "    for threshold in range(1, 255):\n",
    "        # Split histogram\n",
    "        p0 = hist[:threshold]\n",
    "        p1 = hist[threshold:]\n",
    "        \n",
    "        if len(p0) == 0 or len(p1) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Normalize probabilities\n",
    "        p0_norm = p0 / np.sum(p0)\n",
    "        p1_norm = p1 / np.sum(p1)\n",
    "        \n",
    "        # Calculate entropy for both regions\n",
    "        entropy0 = -np.sum(p0_norm * np.log2(p0_norm + np.finfo(float).eps))\n",
    "        entropy1 = -np.sum(p1_norm * np.log2(p1_norm + np.finfo(float).eps))\n",
    "        \n",
    "        # Calculate total entropy\n",
    "        total_entropy = entropy0 + entropy1\n",
    "        \n",
    "        if total_entropy > max_entropy:\n",
    "            max_entropy = total_entropy\n",
    "            optimal_threshold = threshold\n",
    "    \n",
    "    binary = simple_threshold(image, optimal_threshold)\n",
    "    return binary, optimal_threshold\n",
    "\n",
    "def isodata_threshold(image):\n",
    "    \"\"\"Implement ISODATA (Iterative Self-Organizing Data Analysis) algorithm. (AUTO THRESHOLD)\n",
    "    \n",
    "    This method iteratively updates the threshold by:\n",
    "    1. Starting with initial threshold (mean of image)\n",
    "    2. Computing means of pixels above and below threshold\n",
    "    3. Computing new threshold as average of these means\n",
    "    4. Repeating until convergence\n",
    "       \n",
    "    \"\"\"\n",
    "    # Initialize threshold as mean\n",
    "    threshold = np.mean(image)\n",
    "    old_threshold = 0\n",
    "    \n",
    "    # Iterate until convergence\n",
    "    max_iterations = 100\n",
    "    iteration = 0\n",
    "    \n",
    "    while abs(threshold - old_threshold) > 0.5 and iteration < max_iterations:\n",
    "        # Save old threshold\n",
    "        old_threshold = threshold\n",
    "        \n",
    "        # Get pixels in each class\n",
    "        foreground = image[image >= threshold]\n",
    "        background = image[image < threshold]\n",
    "        \n",
    "        # Calculate new threshold as mean of class means\n",
    "        threshold = (np.mean(foreground) + np.mean(background)) / 2\n",
    "        iteration += 1\n",
    "    \n",
    "    binary = simple_threshold(image, threshold)\n",
    "    return binary, threshold\n",
    "\n",
    "def median_threshold(image, offset=0):\n",
    "    \"\"\"Implement median-based thresholding.\n",
    "    \n",
    "    This method uses the median pixel value as the threshold, which is particularly\n",
    "    effective when the image has a balanced distribution of intensities. The offset\n",
    "    parameter allows fine-tuning of the threshold relative to the median.\n",
    "    \"\"\"\n",
    "\n",
    "    threshold = np.median(image) + offset\n",
    "    return (image > threshold).astype(np.uint8) * 255\n",
    "\n",
    "def quartile_threshold(image, quartile=0.75):\n",
    "    \"\"\"Implement quartile-based thresholding.\n",
    "    \n",
    "    Uses a specified quartile of pixel intensities as the threshold. This is useful\n",
    "    when you want to segment based on statistical properties of the intensity\n",
    "    distribution.\n",
    "    \n",
    "    \"\"\"\n",
    "    threshold = np.quantile(image, quartile)\n",
    "    return (image > threshold).astype(np.uint8) * 255\n",
    "\n",
    "def kmeans_threshold(image, k=2, max_iter=100):\n",
    "    \"\"\"Implement k-means based thresholding.\n",
    "    \n",
    "    Uses k-means clustering to group pixels into k intensity clusters, then\n",
    "    uses the boundaries between clusters as thresholds.\n",
    "    \"\"\"\n",
    "    pixels = image.ravel().astype(float)\n",
    "    \n",
    "    # Initialize centroids\n",
    "    min_val, max_val = np.min(pixels), np.max(pixels)\n",
    "    centroids = np.linspace(min_val, max_val, k)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        old_centroids = centroids.copy()\n",
    "        \n",
    "        # Assign pixels to nearest centroid\n",
    "        distances = np.abs(pixels.reshape(-1, 1) - centroids)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Update centroids\n",
    "        for i in range(k):\n",
    "            if np.sum(labels == i) > 0:\n",
    "                centroids[i] = np.mean(pixels[labels == i])\n",
    "        \n",
    "        if np.allclose(old_centroids, centroids):\n",
    "            break\n",
    "    \n",
    "    # Sort centroids and find thresholds between them\n",
    "    centroids.sort()\n",
    "    thresholds = [(centroids[i] + centroids[i+1])/2 for i in range(k-1)]\n",
    "    \n",
    "    # Create binary image using middle threshold if k=2\n",
    "    binary = (image > thresholds[0]).astype(np.uint8) * 255 if k == 2 else None\n",
    "    \n",
    "    return binary, thresholds\n",
    "\n",
    "def fuzzy_threshold(image, c=2, max_iter=100, m=2):\n",
    "    \"\"\"Implement fuzzy c-means thresholding.\n",
    "    \n",
    "    Uses fuzzy c-means clustering to handle uncertainty in pixel classification.\n",
    "    Each pixel can belong to multiple classes with different degrees of membership.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input grayscale image\n",
    "        c (int): Number of clusters\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        m (float): Fuzziness parameter\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (binary_image, threshold)\n",
    "    \"\"\"\n",
    "    pixels = image.ravel().astype(float)\n",
    "    n = len(pixels)\n",
    "    \n",
    "    # Initialize membership matrix\n",
    "    U = np.random.rand(c, n)\n",
    "    U = U / np.sum(U, axis=0)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        old_U = U.copy()\n",
    "        \n",
    "        # Calculate cluster centers\n",
    "        U_m = U ** m\n",
    "        centers = np.sum(U_m * pixels, axis=1) / np.sum(U_m, axis=1)\n",
    "        \n",
    "        # Update membership matrix\n",
    "        for i in range(c):\n",
    "            distances = np.abs(pixels - centers[i])\n",
    "            for j in range(c):\n",
    "                distances_j = np.abs(pixels - centers[j])\n",
    "                U[i] = 1 / np.sum((distances/distances_j)**(2/(m-1)), axis=0)\n",
    "        \n",
    "        if np.allclose(old_U, U):\n",
    "            break\n",
    "    \n",
    "    centers.sort()\n",
    "    threshold = np.mean(centers)\n",
    "    \n",
    "    return (image > threshold).astype(np.uint8) * 255, threshold\n",
    "\n",
    "def wavelet_threshold(image, wavelet='haar', level=1):\n",
    "    \"\"\"Implement wavelet-based thresholding.\n",
    "    \n",
    "    Uses wavelet transform to analyze image at different scales and determine\n",
    "    threshold based on wavelet coefficients.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pywt\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install PyWavelets: pip install PyWavelets\")\n",
    "    \n",
    "    # Perform wavelet decomposition\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "    \n",
    "    # Calculate threshold using detail coefficients\n",
    "    detail_coeffs = list(coeffs[1:])\n",
    "    threshold = np.sqrt(2 * np.log(image.size))\n",
    "    \n",
    "    # Apply threshold to coefficients\n",
    "    threshold_value = np.mean([np.median(np.abs(d)) * threshold for d in detail_coeffs])\n",
    "    \n",
    "    return (image > threshold_value).astype(np.uint8) * 255, threshold_value\n",
    "\n",
    "def bernsen_threshold(image, window_size=15, contrast_threshold=15):\n",
    "    \"\"\"Implement Bernsen's local thresholding method.\n",
    "    \n",
    "    Uses local contrast in a window to determine threshold. If contrast is too low,\n",
    "    the pixel is set based on the global threshold.\n",
    "    \n",
    "    \"\"\"\n",
    "    rows, cols = image.shape\n",
    "    output = np.zeros_like(image)\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    # Pad image\n",
    "    padded = np.pad(image, pad, mode='reflect')\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Extract window\n",
    "            window = padded[i:i+window_size, j:j+window_size]\n",
    "            min_val = np.min(window)\n",
    "            max_val = np.max(window)\n",
    "            \n",
    "            # Calculate local contrast\n",
    "            contrast = max_val - min_val\n",
    "            local_threshold = (min_val + max_val) / 2\n",
    "            \n",
    "            if contrast < contrast_threshold:\n",
    "                # Use global threshold if contrast is too low\n",
    "                output[i, j] = 255 if image[i, j] > np.mean(image) else 0\n",
    "            else:\n",
    "                output[i, j] = 255 if image[i, j] > local_threshold else 0\n",
    "                \n",
    "    return output\n",
    "\n",
    "def mean_shift_threshold(image, bandwidth=30):\n",
    "    \"\"\"Implement mean-shift based thresholding.\n",
    "    \n",
    "    Uses mean-shift clustering to find modes in the intensity distribution\n",
    "    and determine thresholds.\n",
    "    \n",
    "    \"\"\"\n",
    "    intensities = image.ravel()\n",
    "    \n",
    "    current_means = np.random.choice(intensities, size=10)\n",
    "    \n",
    "    # Mean-shift iteration\n",
    "    for _ in range(20):\n",
    "        for i in range(len(current_means)):\n",
    "            distances = np.abs(intensities - current_means[i])\n",
    "            weights = np.exp(-0.5 * (distances / bandwidth) ** 2)\n",
    "            \n",
    "            # Update mean\n",
    "            current_means[i] = np.sum(intensities * weights) / np.sum(weights)\n",
    "    \n",
    "    # Find unique modes\n",
    "    modes = np.unique(np.round(current_means))\n",
    "    \n",
    "    # Use middle value as threshold for binary image\n",
    "    threshold = np.median(modes)\n",
    "    \n",
    "    return (image > threshold).astype(np.uint8) * 255, threshold\n",
    "\n",
    "def gradient_threshold(image, k=1, sigma=1.0):\n",
    "    \"\"\"Implement gradient-based thresholding.\n",
    "    \n",
    "    Uses image gradient magnitude to determine threshold. Areas with high\n",
    "    gradient magnitudes often correspond to edges between regions.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate gradients\n",
    "    gx = np.gradient(image, axis=1)\n",
    "    gy = np.gradient(image, axis=0)\n",
    "    \n",
    "    # Calculate gradient magnitude\n",
    "    gradient_mag = np.sqrt(gx**2 + gy**2)\n",
    "    \n",
    "    # Find threshold using gradient magnitude\n",
    "    threshold = np.mean(gradient_mag) + k * np.std(gradient_mag)\n",
    "    \n",
    "    return (image > threshold).astype(np.uint8) * 255, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholding_algorithms = {\n",
    "    'Simple (T=127)': lambda image : simple_threshold(image, 127),\n",
    "    'Mean Adaptive': lambda image : mean_adaptive_threshold(image),\n",
    "    'Gaussian Adaptive': lambda image :gaussian_adaptive_threshold(image),\n",
    "    'Otsu': lambda image :otsu_threshold(image)[0],\n",
    "    'Multilevel': lambda image :multilevel_threshold(image)[0],\n",
    "    'Local': lambda image :local_threshold(image),\n",
    "    'Triangle': lambda image :triangle_threshold(image)[0],\n",
    "    'Entropy': lambda image :entropy_threshold(image)[0],\n",
    "    'ISODATA': lambda image :isodata_threshold(image)[0],\n",
    "    'Median': lambda image: median_threshold(image),\n",
    "    'Quartile': lambda image: quartile_threshold(image),\n",
    "    'K-means': lambda image: kmeans_threshold(image)[0],\n",
    "    'Fuzzy': lambda image: fuzzy_threshold(image)[0],\n",
    "    'Bernsen': lambda image: bernsen_threshold(image),\n",
    "    'Mean-shift': lambda image: mean_shift_threshold(image)[0],\n",
    "    'Gradient': lambda image: gradient_threshold(image)[0]\n",
    "}\n",
    "\n",
    "# Now we can test these algorithms on random images\n",
    "def test_thresholding():\n",
    "    try:\n",
    "        results = process_random_image(\n",
    "            '../images',\n",
    "            thresholding_algorithms,\n",
    "            num_images=1\n",
    "        )\n",
    "        \n",
    "        for result in results:\n",
    "            print(f\"\\nAnalyzing results for {result['filename']}:\")\n",
    "            print(\"Original image statistics:\")\n",
    "            print(f\"Mean intensity: {result['stats']['mean']:.2f}\")\n",
    "            print(f\"Standard deviation: {result['stats']['std']:.2f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "\n",
    "# Run the test\n",
    "test_thresholding()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
